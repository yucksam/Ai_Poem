{
 "cells": [
  {
   "cell_type": "code",
   "id": "ae4ac5e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T03:27:13.884902Z",
     "start_time": "2025-07-06T03:27:13.053449Z"
    }
   },
   "source": [
    "import json\n",
    "import torch\n",
    "from typing import Dict\n",
    "\n",
    "# ====================== 1. 加载词表 ======================\n",
    "def load_vocab(file_path: str) -> Dict[str, int]:\n",
    "\t\"\"\"加载词表映射文件\"\"\"\n",
    "\twith open(file_path, 'r', encoding='utf-8') as f:\n",
    "\t\treturn json.load(f)\n",
    "\n",
    "# 加载词表映射文件\n",
    "token2idx = load_vocab('token2idx.json')\n",
    "idx2token = {int(k): v for k, v in load_vocab('idx2token.json').items()}\n",
    "vocab_size = len(token2idx)\n",
    "\n",
    "# ====================== 2. 加载模型 ======================\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 模型结构定义（必须与训练时一致）\n",
    "class PoemRNN(torch.nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.embed = torch.nn.Embedding(vocab_size, 256)\n",
    "        self.lstm = torch.nn.LSTM(256, 256, num_layers=2, batch_first=True)\n",
    "        self.fc = torch.nn.Linear(256, vocab_size)\n",
    "    \n",
    "    def forward(self, x, hidden=None):\n",
    "        x = self.embed(x)\n",
    "        output, hidden = self.lstm(x, hidden)\n",
    "        return self.fc(output), hidden\n",
    "\n",
    "# 实例化并加载模型权重\n",
    "model = PoemRNN(vocab_size).to(device)\n",
    "model.load_state_dict(torch.load('poem_rnn.pth', map_location=device))\n",
    "model.eval()\n",
    "\n",
    "print(\"数据预加载完成\")\n",
    "print(f\"- 词表大小: {vocab_size}\")\n",
    "print(f\"- 设备: {device}\")\n",
    "print(f\"- 模型架构: {model.__class__.__name__}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据预加载完成\n",
      "- 词表大小: 105569\n",
      "- 设备: cpu\n",
      "- 模型架构: PoemRNN\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "6b410cb0",
   "metadata": {},
   "source": [
    "### 使用温度和TOP_P"
   ]
  },
  {
   "cell_type": "code",
   "id": "a9ade9c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T03:27:29.381587Z",
     "start_time": "2025-07-06T03:27:13.929285Z"
    }
   },
   "source": [
    "import thulac\n",
    "import torch\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "from typing import List, Dict\n",
    "\n",
    "class PoemGenerator:\n",
    "    def __init__(self, \n",
    "                 token2idx: Dict[str, int], \n",
    "                 idx2token: Dict[int, str],\n",
    "                 model: torch.nn.Module,\n",
    "                 device: str = \"cpu\",\n",
    "                 temperature: float = 1.0,\n",
    "                 top_p: float = 0.9):\n",
    "        \n",
    "        self.token2idx = token2idx\n",
    "        self.idx2token = idx2token\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "        self.thulac = thulac.thulac(seg_only=True)\n",
    "        \n",
    "        associations_path: str = \"../word_associations.json\"  # 指定关联词库路径\n",
    "        self.associations = self._load_associations(associations_path)\n",
    "        \n",
    "        # 温度和top_p参数\n",
    "        self.temperature = temperature\n",
    "        self.top_p = top_p\n",
    "\n",
    "    def _load_associations(self, path: str) -> Dict:\n",
    "        \"\"\"从 JSON 文件加载关联词库\"\"\"\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"警告: 未找到关联词库文件 {path}，将使用空字典。\")\n",
    "            return {}\n",
    "        \n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            return json.load(f)\n",
    "\n",
    "    def segment_with_thulac(self, text: str) -> List[str]:\n",
    "        \"\"\"THULAC分词\"\"\"\n",
    "        result = self.thulac.cut(text)\n",
    "        return [word for word, _ in result]\n",
    "\n",
    "    def get_associated_words(self, word: str, top_k: int = 5) -> List[str]:\n",
    "        \"\"\"获取输入词的关联词列表\"\"\"\n",
    "        if word not in self.associations:\n",
    "            return []\n",
    "        # 按权重排序后返回前 top_k 个词\n",
    "        related_words = sorted(\n",
    "            self.associations[word].items(),\n",
    "            key=lambda x: x[1],  # 按权重排序\n",
    "            reverse=True\n",
    "        )\n",
    "        return [w for w, _ in related_words[:top_k]]\n",
    "\n",
    "    def generate_poem(self, prompt: str, max_len: int = 32) -> str:\n",
    "        \"\"\"\n",
    "        生成流程：\n",
    "        1. THULAC分词 -> 2. 本地联想 -> 3. 模型生成\n",
    "        \"\"\"\n",
    "        # 1. 分词\n",
    "        segmented_words = self.segment_with_thulac(prompt)\n",
    "        print(f\"分词结果: {segmented_words}\")\n",
    "        \n",
    "        # 2. 语义联想\n",
    "        all_candidates = []\n",
    "        for word in segmented_words:\n",
    "            all_candidates.append(word)\n",
    "            all_candidates.extend(self.get_associated_words(word))\n",
    "            \n",
    "        print(f\"联想候选词: {all_candidates}\")\n",
    "\n",
    "        # 过滤无效词\n",
    "        valid_words = list(set(w for w in all_candidates if w in self.token2idx))\n",
    "        print(f\"有效候选词: {valid_words}\")\n",
    "        \n",
    "        # 3. 模型生成\n",
    "        if not valid_words:\n",
    "            valid_words = list(self.token2idx.keys())[:10]  # 回退机制\n",
    "            \n",
    "        input_ids = [self.token2idx[valid_words[0]]]\n",
    "        generated = [valid_words[0]]\n",
    "        hidden = None\n",
    "        \n",
    "        for _ in range(max_len - 1):\n",
    "            with torch.no_grad():\n",
    "                inputs = torch.tensor([input_ids[-1:]]).to(self.device)\n",
    "                output, hidden = self.model(inputs, hidden)\n",
    "            \n",
    "            # 动态调整k值\n",
    "            k = min(50, len(self.token2idx))\n",
    "            top_probs, top_indices = torch.topk(output[0, -1], k=k)\n",
    "            \n",
    "            # 使用温度控制概率分布\n",
    "            probs = torch.nn.functional.softmax(top_probs / self.temperature, dim=0)\n",
    "            \n",
    "            # 使用top_p采样\n",
    "            sorted_probs, sorted_indices = torch.sort(probs, descending=True)\n",
    "            cumulative_probs = torch.cumsum(sorted_probs, dim=0)\n",
    "            sorted_indices_to_keep = sorted_indices[cumulative_probs <= self.top_p]\n",
    "            \n",
    "            # 从top_p内的词中选择\n",
    "            valid_indices = sorted_indices_to_keep.tolist()\n",
    "            \n",
    "            # 优先选择候选词\n",
    "            valid_indices.extend(\n",
    "                [idx.item() for idx in top_indices if self.idx2token[idx.item()] in valid_words]\n",
    "            )\n",
    "            \n",
    "            # 回退到普通生成\n",
    "            if not valid_indices:\n",
    "                valid_indices = top_indices[:min(10, k)].tolist()\n",
    "            \n",
    "            next_idx = random.choice(valid_indices)\n",
    "            next_word = self.idx2token[next_idx]\n",
    "            generated.append(next_word)\n",
    "            input_ids.append(next_idx)\n",
    "            \n",
    "            # 随机注入候选词\n",
    "            if random.random() > 0.5 and valid_words:\n",
    "                injected_word = random.choice(valid_words)\n",
    "                generated.append(injected_word)\n",
    "                input_ids.append(self.token2idx[injected_word])\n",
    "        \n",
    "        # 格式化为四行\n",
    "        poem = \"\".join(generated).replace(\"<UNK>\", \"\").replace(\"<EOS>\", \"\")\n",
    "        \n",
    "        # 清理特殊标记\n",
    "        poem = poem.replace(\"<START>\", \"\").replace(\"<PAD>\", \"\").strip()\n",
    "        \n",
    "        lines = [poem[i:i+5] for i in range(0, min(len(poem), 20), 5)]\n",
    "        return \"\\n\".join(lines[:4])\n",
    "\n",
    "# ====================== 使用示例 ======================\n",
    "if __name__ == \"__main__\":\n",
    "    # 初始化生成器\n",
    "    generator = PoemGenerator(\n",
    "        token2idx=token2idx,\n",
    "        idx2token=idx2token,\n",
    "        model=model,\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        temperature=0.7,\n",
    "        top_p=0.9\n",
    "    )\n",
    "    \n",
    "    # 生成古诗\n",
    "    poem = generator.generate_poem(\"春眠不觉晓\", max_len=40)\n",
    "    print(\"生成结果：\")\n",
    "    print(poem)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded succeed\n",
      "分词结果: ['春眠', '不', '觉晓']\n",
      "联想候选词: ['春眠', '不觉', '失晓殊', '可喜', '红日', '晓', '不', '与', '在', '我', '为', '去', '觉晓', '一声', '梦', '鶑', '啼帘', '筛半枕']\n",
      "有效候选词: ['春眠', '与', '不', '为', '一声', '梦', '晓', '鶑', '去', '不觉', '我', '在', '红日', '可喜']\n",
      "生成结果：\n",
      "春眠香岩春\n",
      "眠东归日为\n",
      "东归日南宗\n",
      "我手笔我分\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "ba8af11bf53c6fd5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
